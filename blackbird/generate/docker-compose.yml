services:
  # ollama:
  #   image: ollama/ollama:latest
  #   hostname: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ./models:/root/.ollama/models
  #   # networks:
  #   #   - genai-network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]

  embedder:
    # image: ilopezluna/nomic-embed-text:0.3.8-v1.5
    # image: ghcr.io/huggingface/text-embeddings-inference:1.5
    # image: ISOISS/bge-m3-onnx:latest
    # image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.7
    # image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.5
    image: ghcr.io/huggingface/text-embeddings-inference:cuda-sha-6b79f20
    # command: --model-id nomic-ai/nomic-embed-text-v1.5
    # command: --model-id sentence-transformers/all-MiniLM-L6-v2
    command: --model-id BAAI/bge-small-en-v1.5
    ports:
      - "8090:8090"
    environment:
      - CORS_ALLOW_ORIGIN=http://0.0.0.0:8090
      - PORT=8090
      - MAX_CLIENT_BATCH_SIZE=512      
    volumes:
      - ../../data/embedding:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # burt:
  #   image: leafspider/burt:latest
  #   container_name: burt
  #   environment:
  #     - node.name=burt
  #   ports:
  #     - 5555:5555

#   open-webui:
#     image: ghcr.io/open-webui/open-webui:main
#     ports:
#       - "3000:8080"
#     environment:
#       - OLLAMA_BASE_URL=http://ollama:11434
#     volumes:
#       - ./backend/data:/app/backend/data
#     networks:
#       - genai-network
# networks:
#   genai-network:
#     driver: bridge
#     name: genai-network